<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Bin Li" />


<title>A Summary about Hypothesis Testing</title>

<script src="site_libs/header-attrs-2.7/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">HT summary</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">A Summary about Hypothesis Testing</h1>
<h4 class="author">Bin Li</h4>

</div>


<div id="definition-of-hypothesis-testing" class="section level4">
<h4>1. Definition of hypothesis testing</h4>
<p>Hypothesis testing is a statistical procedure to assess the evidence provided by the data in favor of some claim about a population parameter, like mean. In other words, it uses sample data to draw inference about the population parameter.<br />
<br> For example, it has been believed that the mean SAT math score is 470. If now, the mean STA math score of 1000 student selected randomly is 480. Can we make conclusion that students’ math skills have been improved? <br> <br></p>
</div>
<div id="framework-for-hypothesis-testing" class="section level4">
<h4>2. Framework for Hypothesis Testing</h4>
<p><strong>(1) Set up hypotheses</strong> <br></p>
<p>A null hypothesis and an alternative hypothesis are needed. <strong>Null hypothesis</strong> is the statement being tested in terms of the population parameter. It always claims “no change”, or “no effect”. <strong>Alternative hypothesis</strong> is what we want to establish based on the sample data we observed. It usually associates with changes or differences in the believed value of the interested parameter. If the alternative hypothesis is about “greater” or “less than” question, then it’s a one-sided test. If it’s “not equal” , then it is a two-sided test. <br></p>
<p><strong>(2) Calculate test statistic</strong> <br></p>
<p>A test statistic based on a specific distribution is used to assess how far an estimate of the parameter is from the believed value under null hypothesis. <br></p>
<p><strong>(3) Compute the probability</strong> <br></p>
<p>The probability of observed evidence against the null hypothesis can be calculated assuming that the null hypothesis is true. This probability is also called p-value. <br></p>
<p><strong>(4) Make a conclusion</strong> <br></p>
<p>If the probability of observed evidence is large when we assume the null is true, then we know the sample value of the parameter is likely to be obtained. We don’t have enough evidence to reject the null hypothesis. Otherwise, a tiny probability under the null indicates that the null is not true. We need to reject it and conclude that there is a change in the value of the parameter.<br />
<br> We can compare the p-value with a specific significant level, <span class="math inline">\(\alpha\)</span> , or compare the observed test statistics with the critical value under <span class="math inline">\(\alpha\)</span> to draw the conclusion. If the p-value is less than <span class="math inline">\(\alpha\)</span> level or the test statistics is greater than the critical value, then we need to reject the null hypothesis. <br> <br></p>
</div>
<div id="different-type-of-tests" class="section level4">
<h4>3. Different type of tests</h4>
<p>A population usually comes from a specific distribution. And the critical value is also determined under the distribution. For different distributions, different tests should be used. <br></p>
<p><strong>(1) z-test</strong> <br></p>
<p>A z-test should be conducted when the sample data are drawn from a normal distribution and the population standard deviation <span class="math inline">\(\sigma\)</span> is known.<br />
<br> E.g. Suppose STA math score follows normal distribution and the average STA math score is believed to be 470. Now, we randomly select 1000 students from the whole population, and calculate the mean STA math score which is about 480. And the standard deviation of STA math score is assumed to be 120. Do we have enough evidence to conclude that the average STA math score has been improved?<br />
<br></p>
<ul>
<li><p>Hypothesis<br />
<span class="math inline">\(H_{0}\)</span>: There is no change in the mean STA score of the population / <span class="math inline">\(\mu\)</span> = 470<br />
<span class="math inline">\(H_{a}\)</span>: The population mean of STA score is improved / <span class="math inline">\(\mu\)</span> &gt; 470</p></li>
<li><p>Test statistics<br />
<span class="math display">\[z_{obs} = \frac{(\bar{x}-\mu)}{{\sigma}/{\sqrt{n}} } = \frac{(480-470)}{{120}/{\sqrt{1000}} }\]</span> where <span class="math inline">\(\bar{x}\)</span> is sample mean<br />
<span class="math inline">\(\mu\)</span> is population mean<br />
<span class="math inline">\(\sigma\)</span> is population standard deviation <br></p></li>
</ul>
<p>If <span class="math inline">\(z_{obs}\)</span> is greater than the critical value associated with significance level <span class="math inline">\(\alpha\)</span> or p-value is less than <span class="math inline">\(\alpha\)</span>, then we reject <span class="math inline">\(H_{0}\)</span> and conclude that this is an improvement in STA math score. <br> <br></p>
<p><strong>(2) t-test</strong> <br></p>
<p>When the population standard deviation <span class="math inline">\(\sigma\)</span> is unknown, the z-procedures for inference of a population mean <span class="math inline">\(\mu\)</span> cannot be used. If the sample is still drawn randomly from normal distribution and the sample size is large enough, in this case, we use sample standard deviation <span class="math inline">\(S\)</span> as the estimate of <span class="math inline">\(\sigma\)</span>. When <span class="math inline">\(\sigma\)</span> is substituted with <span class="math inline">\(S\)</span>, the ratio <span class="math inline">\(\frac{(\bar{x}-\mu)}{{S}/{\sqrt{n}} }\)</span> does not follow normal distribution anymore. It follows <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n - 1\)</span> degree of freedom. Then, we need to use t-test. <br></p>
<p><strong>One-sample t-test</strong> <br></p>
<p>One-sample t-test tests the sample mean against a known mean. <br></p>
<p>E.g. Suppose, on average, each user in a certain social media has 120 friends. The number of friends is assumed to be normally distributed. We randomly draw 40 users from the population. The sample mean and sample standard deviation is 150 and 180. Can we say the mean number of friends in this social media is changed now? <br></p>
<ul>
<li><p>Hypothesis<br />
<span class="math inline">\(H_{0}\)</span>: There is no change in the mean number of friends / <span class="math inline">\(\mu = 120\)</span><br />
<span class="math inline">\(H_{a}\)</span>: There is a change in the mean number of friends / <span class="math inline">\(\mu \neq 120\)</span><br />
<br></p></li>
<li><p>Test statistics<br />
<span class="math display">\[t_{obs} = \frac{(\bar{x}-\mu)}{{S}/{\sqrt{n}} } = \frac{(150-120)}{{180}/{\sqrt{40}} }\]</span> where <span class="math inline">\(\bar{x}\)</span> is sample mean<br />
<span class="math inline">\(\mu\)</span> is population mean<br />
<span class="math inline">\(S\)</span> is sample standard deviation<br />
<br></p></li>
</ul>
<p>If <span class="math inline">\(t_{obs}\)</span> is greater than the critical value associated with significance level <span class="math inline">\(\alpha\)</span>, or the p-value is less than <span class="math inline">\(\alpha\)</span> level, then we reject <span class="math inline">\(H_{0}\)</span>.<br />
<br></p>
<p><strong>Paired-sample t-test</strong> <br></p>
<p>Sometimes, we have a kind of matched data, where a collection of independent individuals each have two variables measured on them, and the inference goal is based on comparing these two variables. This is where paired t-test is conducted. In this scenario, we usually take the difference of the two variables and use one-sample t-test. The procedure of paired sample t-test is identical to that of one-sample t-test after we use the difference as our target.<br />
<br></p>
<ul>
<li><p>Hypothesis<br />
<span class="math inline">\(H_{0}\)</span>: There is no difference between the means of the two variables<br />
<span class="math inline">\(H_{a}\)</span>: There is a difference between the means of the two variables <span class="math inline">\((\neq, &gt;, &lt;)\)</span><br />
<br></p></li>
<li><p>Test statistic</p></li>
</ul>
<p>The test statistic is <span class="math display">\[t_{obs} = \frac{(diff-0)}{{S_{diff}}/{\sqrt{n}} }\]</span> where diff is the sample difference between the mean of the two variables, and <span class="math inline">\(S_{diff}\)</span> is the standard deviation of the sample difference. <br></p>
<p>Another approach for matched pairs data is <strong>sign test</strong>, a nonparametric method. There is no distribution assumption in sign test. It assumes that observations are independent and they have a common true median. For example, we want to test if one group has a higher median value than the other group. The general steps are as follows: <br></p>
<ul>
<li><p>Hypothesis<br />
<span class="math inline">\(H_{0}\)</span>: Both groups are equally likely to be observed / <span class="math inline">\(p = 0.5\)</span> / the population median of paired differences is zero<br />
<span class="math inline">\(H_{a}\)</span>: One group is more likely to be observed / <span class="math inline">\(p &gt; 0.5\)</span> / the population median of paired differences is greater zero<br />
<br></p></li>
<li><p>Test statistic</p></li>
</ul>
<p>The test statistic for the sign test is the count, X, of pairs with a positive difference. Under the null hypothesis, the distribution of the test statistic is binomial with sample size <span class="math inline">\(n\)</span> and probability <span class="math inline">\(p = 0.5\)</span>, <span class="math inline">\(Bin(n, 0.5)\)</span>. The p-value for the observed sign test statistic is <span class="math inline">\(P(X \ge test statistic)\)</span> under <span class="math inline">\(Bin(n, 0.5)\)</span>. <br></p>
<p>If the p-value is less than significance level, then we reject the null. <br></p>
<p><strong>Two-sample t-test</strong> <br></p>
<p>Sometimes, we want to compare the means of a sample from each of two independent populations. For example, we have 200 observations. 100 of them are from population 1 and the other 100 are from population 2. The two populations may be from the same distribution family with similar shape, similar spread but different centers. And we are usually interested in the population mean difference and want to know if the difference, <span class="math inline">\(\delta = \mu_{1} - \mu_{2}\)</span>, is zero. And we use sample mean, <span class="math inline">\(\bar{Y_{1}} - \bar{Y_{2}}\)</span>, as the point estimate of <span class="math inline">\(\delta\)</span>. So, if the population distributions are normal with unknown means <span class="math inline">\(\mu_{1}, \mu_{2}\)</span> and unknown standard deviation, and the two samples are independent of one another, then we would use two-sample t procedure to run the test.<br />
<br></p>
<ul>
<li><p>Hypothesis<br />
<span class="math inline">\(H_{0}\)</span>: <span class="math inline">\(\mu_{1} - \mu_{2} = 0\)</span><br />
<span class="math inline">\(H_{a}\)</span>: <span class="math inline">\(\mu_{1} - \mu_{2} \neq 0\)</span> / <span class="math inline">\(\mu_{1} - \mu_{2} &gt; 0\)</span> / <span class="math inline">\(\mu_{1} - \mu_{2} &lt; 0\)</span><br />
<br></p></li>
<li><p>Test statistic</p></li>
</ul>
<p>Depending on if the standard deviation of the two population is equal nor not, we will have different standard error and degree of freedom. <br></p>
<p>The test statistic for <strong>equal variance</strong> t-test is <span class="math display">\[t_{obs} = \frac{\bar{Y_{1}} - \bar{Y_{2}}-(\mu_{1} - \mu_{2})}{{S_{p}}/{\sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}} } \]</span></p>
<p>where <span class="math inline">\(S_{p} = \sqrt{\frac{(n_{1}-1)S_{1}^2 + (n_{2}-1)S_{2}^2}{n_{1} +n_{2} -2}}\)</span><br />
<span class="math inline">\(S_{1}\)</span> and <span class="math inline">\(S_{2}\)</span> are standard deviation of observations from population 1 and population 2 respectively.<br />
<br></p>
<p>Degree of freedom is <span class="math inline">\(df = n_{1} + n_{2} - 2\)</span><br />
<br></p>
<p>The test statistic for <strong>unequal variance</strong> t-test is</p>
<p><span class="math display">\[t_{obs} = \frac{\bar{Y_{1}} - \bar{Y_{2}}-(\mu_{1} - \mu_{2})}{{\sqrt{\frac{S_{1}^2}{n_{1}} + \frac{S_{2}^2}{n_{2}}}} } \]</span></p>
<p>Degree of freedom is <span class="math display">\[df = \frac{(\frac{S_{1}^2}{n_{1}} + \frac{S_{2}^2}{n_{2}})^2}{\frac{(\frac{S_{1}^2}{n_{1}})^2} {n_{1} - 1} + \frac{(\frac{S_{2}^2}{n_{2}})^2} {n_{2} - 1}}\]</span></p>
<p><br></p>
<p><strong>(3) One-way ANOVA</strong> <br></p>
<p>When we compare the means of two categories we could use two-sample t-test. When we have more than two categories, ANOVA approach is applied. ANOVA is short for “analysis of variance”. Although the name is about variance, it is still a test about differences in means. And the differences in means are assessed by comparing the amounts of variability explained by different sources. <br></p>
<p>It assumes that observations are independent and all from normal distribution with equal variance. <br></p>
<ul>
<li><p>Hypothesis<br />
<span class="math inline">\(H_{0}\)</span>: All means are equal<br />
<span class="math inline">\(H_{a}\)</span>: At least one pair of means is not equal<br />
<br></p></li>
<li><p>Test Statistic</p></li>
</ul>
<p>The test statistic is <span class="math inline">\({\frac{MS_{trt}}{MSE}}\)</span> ~ <span class="math inline">\(F_{a-1, N-a}\)</span>. <span class="math inline">\(a\)</span> is the number of category and <span class="math inline">\(N\)</span> is the total number of observations. There are functions in software to run ANOVA test. It can be done easily. <br></p>
<p><strong>(4) Chi-squared test</strong> <br></p>
<p>Chi-squared test is commonly used to test the independent relationship between two categorical variables. <br></p>
<ul>
<li><p>Hypothesis<br />
<span class="math inline">\(H_{0}\)</span>: Variable A and variable B are independent<br />
<span class="math inline">\(H_{a}\)</span>: Variable A and variable b are not independent<br />
<br></p></li>
<li><p>Test Statistic</p></li>
</ul>
<p>The test statistic is <span class="math inline">\(\chi^2 = \sum\frac{(O_{i} - E_{i})^2}{E_{i}}\)</span>. <span class="math inline">\(O_{i}\)</span> is observed value and <span class="math inline">\(E_{i}\)</span> is expected value. Degree of freedom is <span class="math inline">\(df = (r-1)(c-1)\)</span>. <span class="math inline">\(r\)</span> and <span class="math inline">\(c\)</span> are the number of levels in variable A and B respectively.<br />
<br></p>
<p>This is a summary for hypothesis testing only. You can find examples about ANOVA F-test and Chi-squared test for independence in “dough rising” example and “categorical data analysis” section.</p>
<p><br> <br> <br> <br></p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
